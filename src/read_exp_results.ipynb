{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--data-train\", type=str, default='', help=\"training data json\")\n",
    "parser.add_argument(\"--data-val\", type=str, default='', help=\"validation data json\")\n",
    "parser.add_argument(\"--data-eval\", type=str, default='', help=\"evaluation data json\")\n",
    "parser.add_argument(\"--label-csv\", type=str, default='', help=\"csv with class labels\")\n",
    "parser.add_argument(\"--n_class\", type=int, default=527, help=\"number of classes\")\n",
    "parser.add_argument(\"--model\", type=str, default='ast', help=\"the model used\")\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"audioset\", help=\"the dataset used\", choices=[\"audioset\",\"audioset_s\", \"esc50\", \"speechcommands\"])\n",
    "parser.add_argument(\"--n_mels\", type=int, default=128, help=\"number of mel bins\")\n",
    "\n",
    "parser.add_argument(\"--exp-dir\", type=str, default=\"\", help=\"directory to dump experiments\")\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float, metavar='LR', help='initial learning rate')\n",
    "parser.add_argument(\"--optim\", type=str, default=\"adam\", help=\"training optimizer\", choices=[\"sgd\", \"adam\"])\n",
    "parser.add_argument('-b', '--batch-size', default=12, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('-w', '--num-workers', default=32, type=int, metavar='NW', help='# of workers for dataloading (default: 32)')\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=1, help=\"number of maximum training epochs\")\n",
    "# not used in the formal experiments\n",
    "parser.add_argument(\"--lr_patience\", type=int, default=2, help=\"how many epoch to wait to reduce lr if mAP doesn't improve\")\n",
    "\n",
    "parser.add_argument(\"--n-print-steps\", type=int, default=100, help=\"number of steps to print statistics\")\n",
    "parser.add_argument('--save_model', help='save the model or not', type=ast.literal_eval)\n",
    "\n",
    "parser.add_argument('--freqm', help='frequency mask max length', type=int, default=0)\n",
    "parser.add_argument('--timem', help='time mask max length', type=int, default=0)\n",
    "parser.add_argument(\"--mixup\", type=float, default=0, help=\"how many (0-1) samples need to be mixup during training\")\n",
    "parser.add_argument(\"--bal\", type=str, default=None, help=\"use balanced sampling or not\")\n",
    "# the stride used in patch spliting, e.g., for patch size 16*16, a stride of 16 means no overlapping, a stride of 10 means overlap of 6.\n",
    "parser.add_argument(\"--fstride\", type=int, default=10, help=\"soft split freq stride, overlap=patch_size-stride\")\n",
    "parser.add_argument(\"--tstride\", type=int, default=10, help=\"soft split time stride, overlap=patch_size-stride\")\n",
    "parser.add_argument('--imagenet_pretrain', help='if use ImageNet pretrained audio spectrogram transformer model', type=ast.literal_eval, default='True')\n",
    "parser.add_argument('--audioset_pretrain', help='if use ImageNet and audioset pretrained audio spectrogram transformer model', type=ast.literal_eval, default='False')\n",
    "\n",
    "args = parser.parse_args(args=['--model=ast','--init_lr=4e-4','--fusion_module=0','--embedding_size=1024','--pooling=att','--n_trans_layers=2', '--batch_size=100', '--ckpt_size=2500', '--n_conv_layers=10', '--n_pool_layers=5', '--gradient_accumulation=3','--max_ckpt=7', '--scheduler=warmup-decay',\n",
    "                              '--additional_outname=AST_debug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = './audioset-full-f10-t10-pTrue-b48-lr1e-5-42.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(exp_id, 'stats_2.pickle'), 'rb') as f:\n",
    "    data = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mAP = 0\n",
    "result_AP = []\n",
    "for item in data:\n",
    "    result_AP.append(item['AP'])\n",
    "final_mAP = np.mean(result_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41440709598094794\n"
     ]
    }
   ],
   "source": [
    "print(final_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(exp_id, 'predictions', 'target.csv'), 'rb') as csv_f:\n",
    "#     csv_reader = csv.DictReader(csv_f)\n",
    "    lines = csv_f.readlines()\n",
    "    print(np.(lines[0]))\n",
    "#     print(csv_reader)\n",
    "#     for row in lines:\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(exp_id, 'progress.pkl'), 'rb') as f:\n",
    "    progress = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch, global_step, best_epoch, best_mAP, time.time() - start_tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 42099, 1, 0.3707810907863, 21912.47863149643]\n",
      "[2, 84198, 2, 0.41440709598094794, 43810.69362401962]\n",
      "[3, 126297, 3, 0.42908848636897573, 65835.93561148643]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(item) for item in progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
